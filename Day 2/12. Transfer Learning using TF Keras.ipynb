{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with TensorFlow/Keras 2.0 \n",
    "\n",
    "In this example we'll implement fine-tuning and feature extracting transfer learning using the CIFAR-10 dataset. \n",
    "\n",
    "_This example is partially based on_ [https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_datasets\n",
      "  Downloading tensorflow_datasets-3.2.1-py3-none-any.whl (3.4 MB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.2.zip (177 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from tensorflow_datasets) (1.12.1)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from tensorflow_datasets) (1.15.0)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from tensorflow_datasets) (2.24.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.48.2-py2.py3-none-any.whl (68 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from tensorflow_datasets) (0.9.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from tensorflow_datasets) (19.3.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-0.23.0-py3-none-any.whl (43 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from tensorflow_datasets) (1.19.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from tensorflow_datasets) (3.12.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.10)\n",
      "Collecting googleapis-common-protos\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\envs\\dl\\lib\\site-packages (from protobuf>=3.6.1->tensorflow_datasets) (49.2.0.post20200714)\n",
      "Building wheels for collected packages: dill, future, promise\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.2-py3-none-any.whl size=78977 sha256=6e8a5b1cfdd376b942ca6c651ec9e9b6fafc55e2ae4cd3f52eacc8935a5c1030\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\72\\6b\\d5\\5548aa1b73b8c3d176ea13f9f92066b02e82141549d90e2100\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491062 sha256=e230024d34b8ea02d660f54a8feb1986c1400627096493c49e50d29ddc7ea2af\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\56\\b0\\fe\\4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21499 sha256=8789622dcf54d885ca9dc753cf52323170bde9e4a2c37109608d37d42cfdcd5d\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\29\\93\\c6\\762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
      "Successfully built dill future promise\n",
      "Installing collected packages: dill, future, promise, tqdm, googleapis-common-protos, tensorflow-metadata, tensorflow-datasets\n",
      "Successfully installed dill-0.3.2 future-0.18.2 googleapis-common-protos-1.52.0 promise-2.3 tensorflow-datasets-3.2.1 tensorflow-metadata-0.23.0 tqdm-4.48.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: tensorflow-metadata 0.23.0 has requirement absl-py<0.9,>=0.7, but you'll have absl-py 0.9.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define the input image and batch size as constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224  #don't change this !!!\n",
    "BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll continue by loading the CIFAR-10 dataset using the `tensorflow_datasets` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset cifar10/3.0.2 (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\dell\\tensorflow_datasets\\cifar10\\3.0.2...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78d0ca57d664c64a74118fc05ad3df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052f54acf0a14c3182a525798e52c903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d107fe068a4da6acaec34f37ade817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to C:\\Users\\dell\\tensorflow_datasets\\cifar10\\3.0.2.incompleteO23IZS\\cifar10-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ff8e8f754e45bcbfe9639d30b0d3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to C:\\Users\\dell\\tensorflow_datasets\\cifar10\\3.0.2.incompleteO23IZS\\cifar10-test.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b40e14b69ac4a3ba60e12dccea91300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cifar10 downloaded and prepared to C:\\Users\\dell\\tensorflow_datasets\\cifar10\\3.0.2. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data, metadata = tfds.load('cifar10', with_info=True, as_supervised=True)\n",
    "\n",
    "raw_train, raw_test = data['train'].repeat(), data['test'].repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define the input transformations (per sample) for the training and validation phases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_format_sample(image, label):\n",
    "    \"\"\"Transform data for training\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = (image / 127.5) - 1\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "\n",
    "    label = tf.one_hot(label, metadata.features['label'].num_classes)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def test_format_sample(image, label):\n",
    "    \"\"\"Transform data for testing\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = (image / 127.5) - 1\n",
    "\n",
    "    label = tf.one_hot(label, metadata.features['label'].num_classes)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll define the training and validation data providers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign transformers to raw data\n",
    "train_data = raw_train.map(train_format_sample)\n",
    "test_data = raw_test.map(test_format_sample)\n",
    "\n",
    "# extract batches from the training set\n",
    "train_batches = train_data.shuffle(1000).batch(BATCH_SIZE)\n",
    "test_batches = test_data.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define 2 functions that build transfer learning models for either feature extacting, or fine-tuning. Both models use the `tf.keras.applications.ResNet50V2` ImageNet pretrained model. We'll start with feature extracting, which \"locks\" all model parameters (weights) except for the final fully-connected layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fe_model():\n",
    "    \"\"\"\"Create feature extraction model from the pre-trained model ResNet50V2\"\"\"\n",
    "\n",
    "    # create the pre-trained part of the network, excluding FC layers\n",
    "    base_model = tf.keras.applications.ResNet50V2(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                                                  include_top=False,\n",
    "                                                  weights='imagenet')\n",
    "\n",
    "    # exclude all model layers from training\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # create new model as a combination of the pre-trained net\n",
    "    # and one fully connected layer at the top\n",
    "    return tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(\n",
    "            metadata.features['label'].num_classes,\n",
    "            activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll continue with the fine-tuning model, which locks the first `fine_tune_at` layers, but trains all other model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ft_model():\n",
    "    \"\"\"\"Create fine tuning model from the pre-trained model ResNet50V2\"\"\"\n",
    "\n",
    "    # create the pre-trained part of the network, excluding FC layers\n",
    "    base_model = tf.keras.applications.ResNet50V2(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                                                  include_top=False,\n",
    "                                                  weights='imagenet')\n",
    "\n",
    "    # Fine tune from this layer onwards\n",
    "    fine_tune_at = 100\n",
    "\n",
    "    # Freeze all the layers before the `fine_tune_at` layer\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # create new model as a combination of the pre-trained net\n",
    "    # and one fully connected layer at the top\n",
    "    return tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(\n",
    "            metadata.features['label'].num_classes,\n",
    "            activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the `train_model` function, which builds takes the pre-built model, fits it over the training data, and plots the training and validation results. The function is shared for both feature extraction and fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs=5):\n",
    "    \"\"\"Train the model. This function is shared for both FE and FT modes\"\"\"\n",
    "\n",
    "    # configure the model for training\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # train the model\n",
    "    history = model.fit(train_batches,\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=metadata.splits['train'].num_examples // BATCH_SIZE,\n",
    "                        validation_data=test_batches,\n",
    "                        validation_steps=metadata.splits['test'].num_examples // BATCH_SIZE,\n",
    "                        workers=4)\n",
    "\n",
    "    # plot accuracy\n",
    "    test_acc = history.history['val_accuracy']\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(test_acc)\n",
    "    plt.xticks(\n",
    "        [i for i in range(0, len(test_acc))],\n",
    "        [i + 1 for i in range(0, len(test_acc))])\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the training procedure. Let's start by building the feature extraction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Model)           (None, 7, 7, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 23,585,290\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_fe_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's run the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  44/1000 [>.............................] - ETA: 2:01:50 - loss: 2.4080 - accuracy: 0.1750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-4c7aaa9735fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-64a7708ca715>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, epochs)\u001b[0m\n\u001b[0;32m     13\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_examples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                         workers=4)\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# plot accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DL\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#50000/50 = 1000 >> n0. of iterations (steps) per epoch \n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try the fine-tuning model for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Model)           (None, 7, 7, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 23,585,290\n",
      "Trainable params: 20,580,362\n",
      "Non-trainable params: 3,004,928\n",
      "_________________________________________________________________\n",
      "Train for 1000 steps, validate for 200 steps\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 302s 302ms/step - loss: 0.4756 - accuracy: 0.8367 - val_loss: 0.4555 - val_accuracy: 0.8452\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 295s 295ms/step - loss: 0.2451 - accuracy: 0.9170 - val_loss: 0.4341 - val_accuracy: 0.8588\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 294s 294ms/step - loss: 0.1790 - accuracy: 0.9399 - val_loss: 0.3699 - val_accuracy: 0.8748\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 296s 296ms/step - loss: 0.1474 - accuracy: 0.9502 - val_loss: 0.3978 - val_accuracy: 0.8757\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 294s 294ms/step - loss: 0.1242 - accuracy: 0.9584 - val_loss: 0.3802 - val_accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_ft_model()\n",
    "model.summary()\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning achieves better accuracy, compared to the feature-engineering model. The most likely reason is that the feature-engineering model is constrained to update only the weights of the last hidden layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
